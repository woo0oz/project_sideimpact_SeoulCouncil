"""
ì„œìš¸ì‹œ êµ¬ì˜íšŒ íšŒì˜ë¡ ì•ˆê±´ ì¶”ì¶œ ë° ë¶„ì„ ì‹œìŠ¤í…œ (ìµœì¢… ë²„ì „)

ì£¼ìš” ê¸°ëŠ¥:
1. JSON í˜•íƒœì˜ íšŒì˜ë¡ ë°ì´í„° ì²˜ë¦¬
2. GPT-4o-minië¥¼ í™œìš©í•œ ì „ì²´ ë¬¸ì„œ ì•ˆê±´ ì¶”ì¶œ
3. 8ê°œ ë¶„ì•¼ ìë™ ë¶„ë¥˜ (êµìœ¡, ë¬¸í™”, ë³µì§€, í™˜ê²½, êµí†µ, ì•ˆì „, ê²½ì œ, ë³´ê±´)
4. clik.nanet.go.krì—ì„œ ì˜ì•ˆ ê³µì‹ ë¬¸ì„œ ë§¤ì¹­ ë° URL ì¶”ì¶œ
5. ì‹œë¯¼ ì¹œí™”ì ì¸ ~ìš” ì²´ ë§íˆ¬ë¡œ ì˜í–¥ë„ ì„¤ëª…
6. ì •ì œëœ ê²€ìƒ‰ ê²°ê³¼ í…ìŠ¤íŠ¸ ì œê³µ

ì…ë ¥: raw_content í´ë”ì˜ JSON íŒŒì¼ë“¤
ì¶œë ¥: output_content í´ë”ì˜ ì²˜ë¦¬ëœ JSON íŒŒì¼ë“¤

í™˜ê²½ë³€ìˆ˜ ì„¤ì •:
- OPENAI_API_KEY: OpenAI API í‚¤
- GOOGLE_API_KEY: Google Custom Search API í‚¤ (ì„ íƒì‚¬í•­)
- SEARCH_ENGINE_ID: Google Custom Search Engine ID (ì„ íƒì‚¬í•­)
"""

import pandas as pd
import json
import re
import os
import time
import glob
from openai import OpenAI
import requests
from urllib.parse import quote

# clik.nanet.go.kr ê²€ìƒ‰ í—¬í¼ import
from clik_search_helper import search_clik_with_filters, extract_district_from_title, get_bill_content

# OpenAI ì„¤ì •
OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')
client = OpenAI(api_key=OPENAI_API_KEY)
MODEL_NAME = "gpt-4o-mini"

# Google Custom Search API ì„¤ì • (í´ë°±ìš©)
GOOGLE_API_KEY = os.getenv('GOOGLE_API_KEY')
SEARCH_ENGINE_ID = os.getenv('SEARCH_ENGINE_ID')

def get_district_name_from_comm_id(comm_id):
    """íšŒì˜ë¡ IDì—ì„œ êµ¬ ì´ë¦„ì„ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    district_mapping = {
        'gj': 'ê´‘ì§„êµ¬',
        'gn': 'ê°•ë‚¨êµ¬', 
        'gr': 'êµ¬ë¡œêµ¬',
        'gs': 'ê°•ì„œêµ¬',
        'db': 'ë„ë´‰êµ¬',
        'dm': 'ë™ëŒ€ë¬¸êµ¬',
        'gb': 'ê°•ë¶êµ¬',
        'gc': 'ê¸ˆì²œêµ¬',
        'gd': 'ê°•ë™êµ¬'
    }
    
    # comm_idì—ì„œ ë§¨ ì• 2ê¸€ì ì¶”ì¶œ
    if len(comm_id) >= 2:
        district_code = comm_id[:2].lower()
        return district_mapping.get(district_code, 'ì•Œ ìˆ˜ ì—†ëŠ” êµ¬')
    
    return 'ì•Œ ìˆ˜ ì—†ëŠ” êµ¬'

def load_data_from_json(json_file_path):
    """JSON íŒŒì¼ì—ì„œ ë°ì´í„°ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤."""
    print(f"ğŸ“‚ {json_file_path} íŒŒì¼ì„ ë¡œë“œ ì¤‘...")
    
    with open(json_file_path, 'r', encoding='utf-8') as file:
        data = json.load(file)
    
    processed_data = []
    for item in data:
        try:
            # raw_contentê°€ ë¬¸ìì—´ë¡œ ë˜ì–´ìˆëŠ” ê²½ìš° JSON íŒŒì‹±
            if isinstance(item.get('raw_content'), str):
                raw_content = json.loads(item['raw_content'])
            else:
                raw_content = item.get('raw_content', {})
            
            processed_item = {
                'comm_id': raw_content.get('comm_id', ''),
                'content': raw_content.get('content', '')
            }
            processed_data.append(processed_item)
        except json.JSONDecodeError as e:
            print(f"âš ï¸ JSON íŒŒì‹± ì—ëŸ¬: {e}")
            continue
    
    print(f"âœ… ì´ {len(processed_data)}ê°œì˜ íšŒì˜ë¡ ë°ì´í„° ë¡œë“œ ì™„ë£Œ")
    return processed_data

def extract_all_agendas_with_gpt(content, comm_id):
    """GPTë¥¼ ì‚¬ìš©í•˜ì—¬ íšŒì˜ë¡ ì „ì²´ì—ì„œ ëª¨ë“  ì•ˆê±´ì„ í•œ ë²ˆì— ì¶”ì¶œí•©ë‹ˆë‹¤."""
    prompt = f"""
ë‹¤ìŒì€ ì„œìš¸ì‹œ êµ¬ì˜íšŒ íšŒì˜ë¡ ì „ì²´ ë‚´ìš©ì…ë‹ˆë‹¤. ì´ íšŒì˜ë¡ì—ì„œ ëª¨ë“  ì•ˆê±´ì„ ì°¾ì•„ì„œ ê°ê°ì˜ ì •ë³´ë¥¼ ì¶”ì¶œí•´ì£¼ì„¸ìš”.

íšŒì˜ë¡ ë‚´ìš©:
{content}

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•´ì£¼ì„¸ìš” (JSON ë°°ì—´ í˜•íƒœ):
[
  {{
    "agenda_title": "ì•ˆê±´ ì œëª© (êµ¬ì²´ì ì´ê³  ì •í™•í•œ ì œëª©)",
    "agenda_summary": "ì•ˆê±´ì˜ ìƒì„¸ ë°°ê²½ê³¼ ì£¼ìš” ë‚´ìš©ì„ í¬í•¨í•œ ìš”ì•½ (3-4ë¬¸ì¥ìœ¼ë¡œ êµ¬ì²´ì  ì‚¬ì—…ë‚´ìš©, ì˜ˆì‚°, ì¼ì •, ëŒ€ìƒì§€ì—­ ë“± í¬í•¨)",
    "agenda_impact": "í•´ë‹¹ êµ¬ ì‹œë¯¼ë“¤ì—ê²Œ ì‹¤ì œë¡œ ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ì¹œê·¼í•œ ~ìš” ì²´ë¡œ ì„¤ëª… (ì˜ˆ: '~í•  ìˆ˜ ìˆê²Œ ë˜ì–´ìš”', '~í•˜ê²Œ ëì–´ìš”', '~í•  ì˜ˆì •ì´ì—ìš”' ë“±ì˜ ë§íˆ¬ë¡œ êµ¬ì²´ì  í˜œíƒê³¼ ë³€í™”ì‚¬í•­ ì„¤ëª…)",
    "agenda_interests": ["ë¶„ì•¼1", "ë¶„ì•¼2", "ë¶„ì•¼3"]
  }}
]

ì•ˆê±´ ë¶„ì•¼ëŠ” ë‹¤ìŒ ì¤‘ì—ì„œ ì„ íƒí•´ì£¼ì„¸ìš” (ìµœì†Œ 1ê°œ, ìµœëŒ€ 3ê°œ):
- êµìœ¡: êµìœ¡ì •ì±…, í•™êµ, êµìœ¡ì‹œì„¤ ê´€ë ¨
- ë¬¸í™”: ë¬¸í™”ì‹œì„¤, ë¬¸í™”í–‰ì‚¬, ì˜ˆìˆ , ì²´ìœ¡ ê´€ë ¨  
- ë³µì§€: ì‚¬íšŒë³µì§€, ë…¸ì¸ë³µì§€, ì¥ì• ì¸ë³µì§€ ê´€ë ¨
- í™˜ê²½: í™˜ê²½ë³´í˜¸, ì²­ì†Œ, ê³µì›, ë…¹ì§€ ê´€ë ¨
- êµí†µ: êµí†µì •ì±…, ë„ë¡œ, ì£¼ì°¨, ëŒ€ì¤‘êµí†µ ê´€ë ¨
- ì•ˆì „: ì¹˜ì•ˆ, ë°©ë²”, ì•ˆì „ì‹œì„¤, ì¬ë‚œëŒ€ì‘ ê´€ë ¨
- ê²½ì œ: ê²½ì œì •ì±…, ì§€ì—­ê²½ì œ, ìƒê³µì—… ì§€ì› ê´€ë ¨
- ë³´ê±´: ë³´ê±´ì˜ë£Œ, ì˜ë£Œì‹œì„¤, ê±´ê°•ì¦ì§„ ê´€ë ¨

ë¶„ë¥˜ ì›ì¹™:
* ê°€ëŠ¥í•œ í•œ 1ê°œ ë¶„ì•¼ë¡œ ë¶„ë¥˜
* ì•ˆê±´ì´ ëª…í™•íˆ ì—¬ëŸ¬ ë¶„ì•¼ì— ê±¸ì¹œ ê²½ìš°ì—ë§Œ 2~3ê°œ í—ˆìš©
* í˜•ì‹: ë‹¨ì¼ ë¶„ì•¼ë©´ ["í™˜ê²½"] ë°°ì—´, ë³µìˆ˜ ë¶„ì•¼ë©´ ["í™˜ê²½","ê²½ì œ"] ë°°ì—´ë¡œ ì¶œë ¥

ì£¼ì˜ì‚¬í•­:
1. ì‹¤ì œ ì•ˆê±´ë§Œ ì¶”ì¶œí•˜ê³ , ì ˆì°¨ì ì¸ ë‚´ìš©(íšŒì˜ ê°œíšŒ, ííšŒ, ì„œëª…ì˜ì› ì„ ì„ ë“±)ì€ ì œì™¸
2. ê°™ì€ ì•ˆê±´ì´ ì¤‘ë³µë˜ì§€ ì•Šë„ë¡ ì£¼ì˜
3. ì•ˆê±´ì´ ì—†ê±°ë‚˜ ì¶”ì¶œí•  ìˆ˜ ì—†ìœ¼ë©´ ë¹ˆ ë°°ì—´ []ì„ ë°˜í™˜
4. ê° ì•ˆê±´ì˜ ì œëª©ì€ ìµœëŒ€í•œ êµ¬ì²´ì ì´ê³  ì •í™•í•˜ê²Œ ì‘ì„±
"""

    try:
        print(f"ğŸ¤– GPTë¥¼ ì‚¬ìš©í•˜ì—¬ íšŒì˜ë¡ {comm_id} ì „ì²´ ë¶„ì„ ì¤‘...")
        
        response = client.chat.completions.create(
            model=MODEL_NAME,
            messages=[{"role": "user", "content": prompt}],
            temperature=0.3,
            max_tokens=4000
        )
        
        result_text = response.choices[0].message.content.strip()
        
        # JSON íŒŒì‹± ì‹œë„
        try:
            if result_text.lower() == '[]' or not result_text.strip():
                return []
            
            # ì½”ë“œ ë¸”ë¡ í˜•íƒœì˜ ì‘ë‹µ ì²˜ë¦¬
            if result_text.startswith('```json'):
                # ```json ... ``` í˜•íƒœì—ì„œ JSON ë¶€ë¶„ ì¶”ì¶œ
                json_start = result_text.find('[')
                json_end = result_text.rfind(']') + 1
                if json_start != -1 and json_end != 0:
                    result_text = result_text[json_start:json_end]
                else:
                    print(f"âš ï¸ JSON ì½”ë“œ ë¸”ë¡ì—ì„œ ë°°ì—´ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {result_text[:100]}...")
                    return []
            
            # JSON í˜•íƒœê°€ ì•„ë‹Œ ê²½ìš° ì²˜ë¦¬
            if not result_text.startswith('['):
                print(f"âš ï¸ ì˜ˆìƒí•˜ì§€ ëª»í•œ ì‘ë‹µ í˜•ì‹: {result_text[:100]}...")
                return []
            
            agendas = json.loads(result_text)
            
            # ê²°ê³¼ ê²€ì¦ ë° ì •ì œ
            valid_agendas = []
            for agenda in agendas:
                if isinstance(agenda, dict) and agenda.get('agenda_title') and agenda.get('agenda_summary') and agenda.get('agenda_impact'):
                    # ì ˆì°¨ì  ì•ˆê±´ í•„í„°ë§
                    if not is_procedural_agenda(agenda['agenda_title']):
                        valid_agendas.append(agenda)
                    else:
                        print(f"ğŸ”„ ì ˆì°¨ì  ì•ˆê±´ ì œì™¸: {agenda['agenda_title']}")
            
            print(f"âœ… ì´ {len(valid_agendas)}ê°œì˜ ìœ íš¨í•œ ì•ˆê±´ ì¶”ì¶œ ì™„ë£Œ")
            return valid_agendas
            
        except json.JSONDecodeError as e:
            print(f"âš ï¸ JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
            print(f"ì‘ë‹µ ë‚´ìš©: {result_text[:200]}...")
            return []
            
    except Exception as e:
        print(f"âŒ GPT API í˜¸ì¶œ ì¤‘ ì—ëŸ¬ ë°œìƒ: {e}")
        return []

def clean_search_text(text):
    """ê²€ìƒ‰ ê²°ê³¼ í…ìŠ¤íŠ¸ì—ì„œ ë¶ˆí•„ìš”í•œ ë‚´ìš©ì„ ì œê±°í•©ë‹ˆë‹¤."""
    import re
    from urllib.parse import unquote
    
    # URL ë””ì½”ë”©
    try:
        text = unquote(text, encoding='utf-8')
    except:
        pass
    
    # ë¶ˆí•„ìš”í•œ íŒ¨í„´ ì œê±°
    patterns_to_remove = [
        r'https?://[^\s]+',  # URL ì œê±°
        r'www\.[^\s]+',      # wwwë¡œ ì‹œì‘í•˜ëŠ” ë„ë©”ì¸ ì œê±°
        r'%[0-9A-Fa-f]{2}',  # URL ì¸ì½”ë”© ì”ì—¬ë¬¼ ì œê±°
        r'[ê°€-í£]*ê²Œì„[ê°€-í£]*',  # ê²Œì„ ê´€ë ¨ ê´‘ê³  ì œê±°
        r'ì¹´ì§€ë…¸|ë°”ì¹´ë¼|í…ì‚¬ìŠ¤|í¬ì»¤',  # ë„ë°• ê´€ë ¨ ê´‘ê³  ì œê±°
        r'ì‡¼í•‘ëª°|ë°°ì†¡|ì£¼ë¬¸|ì•„ë§ˆì¡´|11ë²ˆê°€',  # ì‡¼í•‘ ê´€ë ¨ ê´‘ê³  ì œê±°
        r'AD[ê°€-í£]*|ê´‘ê³ [ê°€-í£]*',  # ê´‘ê³  í‘œì‹œ ì œê±°
        r'\s+',  # ì—°ì†ëœ ê³µë°±ì„ í•˜ë‚˜ë¡œ
    ]
    
    for pattern in patterns_to_remove:
        text = re.sub(pattern, ' ', text)
    
    # í•œê¸€, ìˆ«ì, ê¸°ë³¸ ë¬¸ì¥ë¶€í˜¸ë§Œ ìœ ì§€
    text = re.sub(r'[^ê°€-í£0-9a-zA-Z\s.,!?()Â·\-]', ' ', text)
    
    # ì—°ì†ëœ ê³µë°± ì •ë¦¬
    text = re.sub(r'\s+', ' ', text).strip()
    
    # ë„ˆë¬´ ì§§ê±°ë‚˜ ì˜ë¯¸ì—†ëŠ” í…ìŠ¤íŠ¸ í•„í„°ë§
    if len(text) < 10 or not re.search(r'[ê°€-í£]', text):
        return ""
    
    return text

def google_search(query, num_results=3):
    """Google Custom Search APIë¥¼ ì‚¬ìš©í•˜ì—¬ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    if not GOOGLE_API_KEY or not SEARCH_ENGINE_ID:
        print("âš ï¸ Google API í‚¤ ë˜ëŠ” Search Engine IDê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return []
    
    try:
        # ê²€ìƒ‰ ì¿¼ë¦¬ ì •ì œ
        clean_query = query.replace('ì¡°ë¡€ì•ˆ', '').replace('ì˜ê±´', '').strip()
        encoded_query = quote(clean_query)
        
        url = f"https://www.googleapis.com/customsearch/v1"
        params = {
            'key': GOOGLE_API_KEY,
            'cx': SEARCH_ENGINE_ID,
            'q': encoded_query,
            'num': num_results,
            'lr': 'lang_ko',  # í•œêµ­ì–´ ê²°ê³¼ë§Œ
            'hl': 'ko'
        }
        
        response = requests.get(url, params=params, timeout=10)
        response.raise_for_status()
        
        search_results = response.json()
        
        # ê²€ìƒ‰ ê²°ê³¼ ì •ë¦¬ - snippetë§Œ ë¬¸ìì—´ë¡œ í•©ì¹˜ê¸°
        snippets = []
        if 'items' in search_results:
            for item in search_results['items']:
                snippet = item.get('snippet', '').strip()
                if snippet:  # ë¹ˆ snippetì€ ì œì™¸
                    # í…ìŠ¤íŠ¸ ì •ì œ
                    cleaned_snippet = clean_search_text(snippet)
                    if cleaned_snippet:  # ì •ì œ í›„ì—ë„ ë‚´ìš©ì´ ìˆìœ¼ë©´
                        snippets.append(cleaned_snippet)
        
        # snippetë“¤ì„ í•˜ë‚˜ì˜ ë¬¸ìì—´ë¡œ í•©ì¹˜ê¸°
        return ' '.join(snippets) if snippets else ""
        
    except requests.exceptions.RequestException as e:
        print(f"âš ï¸ Google ê²€ìƒ‰ API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
        return []
    except Exception as e:
        print(f"âš ï¸ ê²€ìƒ‰ ì¤‘ ì—ëŸ¬ ë°œìƒ: {e}")
        return []



def is_procedural_agenda(title):
    """ì ˆì°¨ì  ì•ˆê±´ì¸ì§€ í™•ì¸í•©ë‹ˆë‹¤."""
    procedural_keywords = [
        'íšŒì˜ë¡ ì„œëª…', 'íšŒì˜ íœ´íšŒ', 'íšŒì˜ ê°œíšŒ', 'íšŒì˜ ì†ê°œ', 'íšŒì˜ ííšŒ',
        'ì„œëª…ì˜ì› ì„ ì„', 'ì˜ì‚¬ì¼ì •', 'íšŒì˜ ì¤‘ë‹¨', 'íšŒì˜ ì¬ê°œ',
        'ìœ„ì›ì¥ ì„ ì¶œ', 'ë¶€ìœ„ì›ì¥ ì„ ì¶œ', 'ê°„ì‚¬ ì„ ì„'
    ]
    
    return any(keyword in title for keyword in procedural_keywords)

def save_results_to_json(results, output_file_path):
    """ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤."""
    print(f"ğŸ’¾ ê²°ê³¼ë¥¼ {output_file_path}ì— ì €ì¥ ì¤‘...")
    
    os.makedirs(os.path.dirname(output_file_path), exist_ok=True)
    
    with open(output_file_path, 'w', encoding='utf-8') as file:
        json.dump(results, file, ensure_ascii=False, indent=2)
    
    print(f"âœ… ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {len(results)}ê°œ ì•ˆê±´")

def generate_agenda_id(comm_id, index):
    """comm_id ê¸°ë°˜ìœ¼ë¡œ ê³ ìœ í•œ agenda_idë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    return f"{comm_id}_{index:03d}"

def main_pipeline(json_file_path, output_path):
    """ì „ì²´ íŒŒì´í”„ë¼ì¸ì„ ì‹¤í–‰í•©ë‹ˆë‹¤."""
    file_start_time = time.time()
    filename = os.path.basename(json_file_path).replace('.json', '')
    print(f"\nğŸš€ íŒŒì¼ ì²˜ë¦¬ ì‹œì‘: {filename}")
    
    # 1. ë°ì´í„° ë¡œë“œ
    data = load_data_from_json(json_file_path)
    
    all_results = []
    total_meetings = len(data)
    total_agendas_found = 0
    total_agendas_processed = 0
    
    # ì „ì²´ íšŒì˜ë¡ ì²˜ë¦¬
    print(f"ğŸ“Š ì´ {total_meetings}ê°œì˜ íšŒì˜ë¡ ì²˜ë¦¬ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤.")
    
    for meeting_idx, meeting in enumerate(data, 1):
        meeting_start_time = time.time()
        comm_id = meeting['comm_id']
        content = meeting['content']
        
        # êµ¬ ì´ë¦„ ì¶”ì¶œ
        district_name = get_district_name_from_comm_id(comm_id)
        
        print(f"\n--- {meeting_idx}/{total_meetings} íšŒì˜ë¡ ì²˜ë¦¬ ì‹œì‘ (íšŒì˜ë¡ID: {comm_id}, êµ¬ì˜íšŒ: {district_name}) ---")
        
        # 2. GPTë¥¼ ì‚¬ìš©í•˜ì—¬ íšŒì˜ë¡ ì „ì²´ì—ì„œ ëª¨ë“  ì•ˆê±´ ì¶”ì¶œ
        extracted_agendas = extract_all_agendas_with_gpt(content, comm_id)
        
        if not extracted_agendas:
            print("âš ï¸ ì¶”ì¶œëœ ì•ˆê±´ì´ ì—†ìŠµë‹ˆë‹¤.")
            meeting_elapsed = time.time() - meeting_start_time
            print(f"âœ… {comm_id} ì²˜ë¦¬ ì™„ë£Œ | ì¶”ì¶œëœ ì•ˆê±´: 0ê°œ | ì†Œìš”ì‹œê°„: {meeting_elapsed:.2f}ì´ˆ")
            continue
        
        print(f"ğŸ“‘ íšŒì˜ë¡ {comm_id}ì—ì„œ {len(extracted_agendas)}ê°œì˜ ì•ˆê±´ì„ ì¶”ì¶œí–ˆìŠµë‹ˆë‹¤.")
        
        meeting_agendas = 0
        
        # 3. ê° ì•ˆê±´ì— ëŒ€í•´ clik.nanet.go.krì—ì„œ ì˜ì•ˆ ê²€ìƒ‰ ë° ê²°ê³¼ êµ¬ì„±
        for agenda_idx, agenda_info in enumerate(extracted_agendas, 1):
            agenda_title = agenda_info['agenda_title']
            
            print(f"ğŸ” '{agenda_title}' clik.nanet.go.krì—ì„œ ì˜ì•ˆ ê²€ìƒ‰ ì¤‘...")
            
            # êµ¬ ì´ë¦„ ì¶”ì¶œ (comm_idì™€ title ëª¨ë‘ì—ì„œ)
            district_from_id = get_district_name_from_comm_id(comm_id)
            district_from_title = extract_district_from_title(agenda_title)
            
            # comm_id ê¸°ë°˜ êµ¬ ì´ë¦„ì„ ìš°ì„  ì‚¬ìš©, ì—†ìœ¼ë©´ ì œëª©ì—ì„œ ì¶”ì¶œ
            district = district_from_title if district_from_title != "ì•Œ ìˆ˜ ì—†ëŠ” êµ¬" else district_from_id
            
            print(f"ğŸ¢ ëŒ€ìƒ êµ¬ì˜íšŒ: {district}")
            
            # clik.nanet.go.krì—ì„œ ì˜ì•ˆ ê²€ìƒ‰
            clik_result = search_clik_with_filters(agenda_title, district)
            
            agenda_url = ""
            agenda_full_text = ""
            
            if clik_result:
                agenda_url = clik_result['url']
                print(f"âœ… ì˜ì•ˆ ë§¤ì¹­ ì„±ê³µ: {clik_result['title']}")
                print(f"ğŸ”— URL: {agenda_url}")
                
                # ì˜ì•ˆ ì „ë¬¸ ë‚´ìš© ê°€ì ¸ì˜¤ê¸°
                agenda_full_text = get_bill_content(agenda_url)
                if agenda_full_text:
                    print(f"ğŸ“„ ì˜ì•ˆ ë‚´ìš© ì¶”ì¶œ: {len(agenda_full_text)}ì")
                else:
                    print("âš ï¸ ì˜ì•ˆ ë‚´ìš© ì¶”ì¶œ ì‹¤íŒ¨ - ìš”ì•½ ì •ë³´ ì‚¬ìš©")
                    agenda_full_text = clik_result.get('summary', '')
            else:
                print("âŒ ë§¤ì¹­ë˜ëŠ” ì˜ì•ˆ ì—†ìŒ - Google Searchë¡œ í´ë°±")
                
                # í´ë°±: Google Custom Search ì‚¬ìš©
                if GOOGLE_API_KEY and SEARCH_ENGINE_ID:
                    search_results = google_search(agenda_title)
                    agenda_full_text = search_results
                else:
                    agenda_full_text = ""
            
            # ì•ˆê±´ ID ìƒì„±
            agenda_id = generate_agenda_id(comm_id, agenda_idx)
            
            # ê²°ê³¼ êµ¬ì„± (ìƒˆë¡œìš´ í˜•ì‹ - agenda_url ì¶”ê°€)
            result = {
                "comm_id": comm_id,
                "value": {
                    "agenda_id": agenda_id,
                    "agenda_title": agenda_title,
                    "agenda_summary": agenda_info['agenda_summary'],
                    "agenda_impact": agenda_info.get('agenda_impact', 'ì‹œë¯¼ë“¤ì—ê²Œ ê¸ì •ì ì¸ ì˜í–¥ì„ ë¯¸ì¹  ê²ƒìœ¼ë¡œ ì˜ˆìƒë©ë‹ˆë‹¤.'),
                    "agenda_interests": agenda_info.get('agenda_interests', []),
                    "agenda_full_text": agenda_full_text,
                    "agenda_url": agenda_url
                }
            }
            
            all_results.append(result)
            meeting_agendas += 1
            total_agendas_processed += 1
            
            print(f"âœ… ì•ˆê±´ ì²˜ë¦¬ ì™„ë£Œ: {agenda_title[:50]}...")
            print(f"ğŸ” ê²€ìƒ‰ ê²°ê³¼: {len(agenda_full_text)}ì")
        
        total_agendas_found += len(extracted_agendas)
        meeting_elapsed = time.time() - meeting_start_time
        print(f"âœ… {comm_id} ì²˜ë¦¬ ì™„ë£Œ | ì¶”ì¶œëœ ì•ˆê±´: {meeting_agendas}ê°œ | ì†Œìš”ì‹œê°„: {meeting_elapsed:.2f}ì´ˆ")
    
    # 4. ê²°ê³¼ ì €ì¥
    output_file_path = os.path.join(output_path, f"{filename}_prep.json")
    save_results_to_json(all_results, output_file_path)
    
    # 5. ìµœì¢… í†µê³„
    file_elapsed = time.time() - file_start_time
    print(f"\nğŸ“Š íŒŒì¼ ì²˜ë¦¬ ì™„ë£Œ í†µê³„:")
    print(f"   â€¢ íŒŒì¼ëª…: {filename}")
    print(f"   â€¢ ì²˜ë¦¬ëœ íšŒì˜ë¡: {total_meetings}ê°œ")
    print(f"   â€¢ íƒì§€ëœ ì•ˆê±´ êµ¬ê°„: {total_agendas_found}ê°œ")
    print(f"   â€¢ ì²˜ë¦¬ëœ ì•ˆê±´: {total_agendas_processed}ê°œ")
    print(f"   â€¢ ì´ ì†Œìš”ì‹œê°„: {file_elapsed:.2f}ì´ˆ")
    print(f"   â€¢ ì €ì¥ ìœ„ì¹˜: {output_file_path}")

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    # í™˜ê²½ ë³€ìˆ˜ í™•ì¸
    if not OPENAI_API_KEY:
        print("âŒ OPENAI_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        exit(1)
    
    if not GOOGLE_API_KEY:
        print("âš ï¸ GOOGLE_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. (í´ë°± ê²€ìƒ‰ ê¸°ëŠ¥ ë¹„í™œì„±í™”)")
        
    if not SEARCH_ENGINE_ID:
        print("âš ï¸ SEARCH_ENGINE_ID í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. (í´ë°± ê²€ìƒ‰ ê¸°ëŠ¥ ë¹„í™œì„±í™”)")
    
    print("ğŸ” clik.nanet.go.kr ì˜ì•ˆ ê²€ìƒ‰ ê¸°ëŠ¥ í™œì„±í™”")
    if GOOGLE_API_KEY and SEARCH_ENGINE_ID:
        print("âœ… Google ê²€ìƒ‰ í´ë°± ê¸°ëŠ¥ í™œì„±í™”")
    else:
        print("âš ï¸ Google ê²€ìƒ‰ í´ë°± ê¸°ëŠ¥ ë¹„í™œì„±í™”")
    
    # ì…ë ¥ ë° ì¶œë ¥ ê²½ë¡œ ì„¤ì •
    input_folder = "raw_content"
    output_folder = "output_content"
    
    # í´ë”ê°€ ì—†ìœ¼ë©´ ìƒì„±
    os.makedirs(output_folder, exist_ok=True)
    
    # JSON íŒŒì¼ ì°¾ê¸°
    json_files = glob.glob(os.path.join(input_folder, "*.json"))
    
    if not json_files:
        print(f"âŒ {input_folder} í´ë”ì— JSON íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        exit(1)
    
    total_start_time = time.time()
    print(f"ğŸ¯ ì „ì²´ ì²˜ë¦¬ ì‹œì‘: {len(json_files)}ê°œ íŒŒì¼")
    
    # ê° JSON íŒŒì¼ ì²˜ë¦¬
    for file_idx, json_file_path in enumerate(json_files, 1):
        print(f"\n{'='*60}")
        
        # íŒŒì¼ëª…ì—ì„œ êµ¬ ì½”ë“œ ì¶”ì¶œ
        filename = os.path.basename(json_file_path).replace('.json', '')
        district_code = filename.split('_')[-1] if '_' in filename else filename[:2]
        district_name = get_district_name_from_comm_id(district_code)
        
        print(f"ğŸ“ {file_idx}/{len(json_files)} íŒŒì¼ ì²˜ë¦¬ ì¤‘... ({district_name})")
        main_pipeline(json_file_path, output_folder)
    
    # ì „ì²´ ì™„ë£Œ í†µê³„
    total_elapsed = time.time() - total_start_time
    print(f"\n{'='*60}")
    print(f"ğŸ‰ ì „ì²´ ì²˜ë¦¬ ì™„ë£Œ!")
    print(f"   â€¢ ì´ íŒŒì¼ ìˆ˜: {len(json_files)}ê°œ")
    print(f"   â€¢ ì´ ì†Œìš”ì‹œê°„: {total_elapsed:.2f}ì´ˆ")
    print(f"   â€¢ í‰ê·  íŒŒì¼ë‹¹ ì‹œê°„: {total_elapsed/len(json_files):.2f}ì´ˆ")
    print(f"   â€¢ ê²°ê³¼ ì €ì¥ í´ë”: {output_folder}")

if __name__ == "__main__":
    """
    ì‹¤í–‰ ë°©ë²•:
    1. í•„ìˆ˜ í™˜ê²½ë³€ìˆ˜ ì„¤ì •:
       - OPENAI_API_KEY
    
    2. ì„ íƒì  í™˜ê²½ë³€ìˆ˜ ì„¤ì • (Google ê²€ìƒ‰ ê¸°ëŠ¥):
       - GOOGLE_API_KEY
       - SEARCH_ENGINE_ID
    
    3. ì‹¤í–‰:
       python meeting_minutes_processor_with_search.py
    
    4. ê²°ê³¼ í™•ì¸:
       output_content í´ë”ì—ì„œ *_prep.json íŒŒì¼ë“¤ í™•ì¸
    """
    main()