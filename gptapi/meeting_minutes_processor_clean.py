"""
ì„œìš¸ì‹œ êµ¬ì˜íšŒ íšŒì˜ë¡ ì•ˆê±´ ì¶”ì¶œ ë° ë¶„ì„ ì‹œìŠ¤í…œ (ì „ì²´ ë‚´ìš© ì²˜ë¦¬ ë²„ì „)

ì£¼ìš” íŠ¹ì§•:
1. Google Custom Search API ì œê±°
2. agenda_full_text: ì•ˆê±´ë³„ ì „ì²´ ë‚´ìš© í¬í•¨
3. agenda_url: comm_id ê¸°ë°˜ íšŒì˜ë¡ URL ë§¤í•‘
4. í† í° ì œí•œ ì—†ìŒ: íšŒì˜ë¡ ì „ì²´ ë‚´ìš©ì„ ì²˜ë¦¬í•˜ì—¬ ëª¨ë“  ì•ˆê±´ ì™„ì „ ì¶”ì¶œ

ì‚¬ìš© ê¶Œì¥:
- ëª¨ë“  ì•ˆê±´ì˜ ì™„ì „í•œ ì¶”ì¶œì´ í•„ìš”í•œ ê²½ìš°
- í”„ë¡œë•ì…˜ í™˜ê²½ ìµœì¢… ê²°ê³¼ë¬¼ ìƒì„±
- ìµœê³  í’ˆì§ˆê³¼ ì™„ì„±ë„ê°€ ì¤‘ìš”í•œ ê²½ìš°

ì…ë ¥: raw_content í´ë”ì˜ JSON íŒŒì¼ë“¤ + tb_meta_info.json
ì¶œë ¥: output_content í´ë”ì˜ ì²˜ë¦¬ëœ JSON íŒŒì¼ë“¤

í™˜ê²½ë³€ìˆ˜ ì„¤ì •:
- OPENAI_API_KEY: OpenAI API í‚¤
"""

import pandas as pd
import json
import re
import os
import time
import glob
from openai import OpenAI

# OpenAI ì„¤ì •
OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')
client = OpenAI(api_key=OPENAI_API_KEY)
MODEL_NAME = "gpt-4o-mini"

def get_district_name_from_comm_id(comm_id):
    """íšŒì˜ë¡ IDì—ì„œ êµ¬ ì´ë¦„ì„ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    district_mapping = {
        'gj': 'ê´‘ì§„êµ¬',
        'gn': 'ê°•ë‚¨êµ¬', 
        'gr': 'êµ¬ë¡œêµ¬',
        'gs': 'ê°•ì„œêµ¬',
        'db': 'ë„ë´‰êµ¬',
        'dm': 'ë™ëŒ€ë¬¸êµ¬',
        'gb': 'ê°•ë¶êµ¬',
        'gc': 'ê¸ˆì²œêµ¬',
        'gd': 'ê°•ë™êµ¬'
    }
    
    # comm_idì—ì„œ ë§¨ ì• 2ê¸€ì ì¶”ì¶œ
    if len(comm_id) >= 2:
        district_code = comm_id[:2].lower()
        return district_mapping.get(district_code, 'ì•Œ ìˆ˜ ì—†ëŠ” êµ¬')
    
    return 'ì•Œ ìˆ˜ ì—†ëŠ” êµ¬'

def load_meta_info(meta_file_path):
    """tb_meta_info.jsonì—ì„œ comm_idì™€ URL ë§¤í•‘ì„ ë¡œë“œí•©ë‹ˆë‹¤."""
    print(f"ğŸ“‚ ë©”íƒ€ ì •ë³´ ë¡œë“œ ì¤‘: {meta_file_path}")
    
    with open(meta_file_path, 'r', encoding='utf-8') as file:
        meta_data = json.load(file)
    
    # comm_idë¥¼ í‚¤ë¡œ í•˜ëŠ” ë”•ì…”ë„ˆë¦¬ ìƒì„±
    comm_id_to_url = {}
    for item in meta_data:
        comm_id = item.get('comm_id', '').strip()
        url = item.get('url', '').strip()
        # comm_idì™€ urlì´ ëª¨ë‘ ìœ íš¨í•˜ê³ , í—¤ë” í–‰ì´ ì•„ë‹Œ ê²½ìš°ë§Œ ì¶”ê°€
        if comm_id and url and comm_id != 'comm_id' and url != 'url':
            comm_id_to_url[comm_id] = url
    
    print(f"âœ… ë©”íƒ€ ì •ë³´ ë¡œë“œ ì™„ë£Œ: {len(comm_id_to_url)}ê°œ comm_id")
    return comm_id_to_url

def load_data_from_json(json_file_path):
    """JSON íŒŒì¼ì—ì„œ ë°ì´í„°ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤."""
    print(f"ğŸ“‚ {json_file_path} íŒŒì¼ì„ ë¡œë“œ ì¤‘...")
    
    with open(json_file_path, 'r', encoding='utf-8') as file:
        data = json.load(file)
    
    processed_data = []
    for item in data:
        try:
            # raw_contentê°€ ë¬¸ìì—´ë¡œ ë˜ì–´ìˆëŠ” ê²½ìš° JSON íŒŒì‹±
            if isinstance(item.get('raw_content'), str):
                raw_content = json.loads(item['raw_content'])
            else:
                raw_content = item.get('raw_content', {})
            
            processed_item = {
                'comm_id': raw_content.get('comm_id', ''),
                'content': raw_content.get('content', '')
            }
            processed_data.append(processed_item)
        except json.JSONDecodeError as e:
            print(f"âš ï¸ JSON íŒŒì‹± ì—ëŸ¬: {e}")
            continue
    
    print(f"âœ… ì´ {len(processed_data)}ê°œì˜ íšŒì˜ë¡ ë°ì´í„° ë¡œë“œ ì™„ë£Œ")
    return processed_data

def fix_json_commas(json_text):
    """ë‹¤ì–‘í•œ JSON comma ë¬¸ì œë¥¼ ìˆ˜ì •í•©ë‹ˆë‹¤."""
    # 1. ê°ì²´ë‚˜ ë°°ì—´ ëì˜ trailing comma ì œê±° (ë” ì •í™•í•œ íŒ¨í„´)
    cleaned = re.sub(r',(\s*[}\]])', r'\1', json_text)
    # 2. ì†ì„±ê°’ ë’¤ì˜ ì˜ëª»ëœ comma ì œê±° (ì—°ì† comma)
    cleaned = re.sub(r',(\s*,)', ',', cleaned)
    # 3. ë§ˆì§€ë§‰ ì†ì„± ë’¤ì˜ comma ì œê±° (ë” ì •êµí•œ íŒ¨í„´)
    cleaned = re.sub(r',(\s*}\s*[,\]])', r'\1', cleaned)
    # 4. ì¤„ë°”ê¿ˆì´ ìˆëŠ” trailing comma ì œê±°
    cleaned = re.sub(r',\s*\n\s*}', '\n}', cleaned)
    cleaned = re.sub(r',\s*\n\s*]', '\n]', cleaned)
    return cleaned

def fix_incomplete_json(json_text):
    """ë¶ˆì™„ì „í•œ JSONì„ ìˆ˜ì •í•©ë‹ˆë‹¤."""
    cleaned = fix_json_commas(json_text)
    
    # ë§ˆì§€ë§‰ì— ë¶ˆì™„ì „í•œ ê°ì²´ê°€ ìˆìœ¼ë©´ ì œê±°
    if cleaned.count('{') > cleaned.count('}'):
        # ë§ˆì§€ë§‰ ì™„ì „í•œ ê°ì²´ê¹Œì§€ë§Œ ìœ ì§€
        last_complete = cleaned.rfind('}')
        if last_complete > 0:
            # ë°°ì—´ì˜ ëì„ ì°¾ì•„ì„œ ì ì ˆíˆ ë‹«ê¸°
            after_last_brace = cleaned[last_complete+1:]
            if ']' not in after_last_brace:
                cleaned = cleaned[:last_complete+1] + '\n]'
    
    return cleaned

def extract_all_agendas_with_gpt(content, comm_id):
    """GPTë¥¼ ì‚¬ìš©í•˜ì—¬ íšŒì˜ë¡ ì „ì²´ì—ì„œ ëª¨ë“  ì•ˆê±´ì„ í•œ ë²ˆì— ì¶”ì¶œí•©ë‹ˆë‹¤."""
    
    print(f"ğŸ“„ ì „ì²´ íšŒì˜ë¡ ë‚´ìš©ì„ í•œ ë²ˆì— ì²˜ë¦¬í•©ë‹ˆë‹¤: {len(content):,}ì")
    
    prompt = f"""
ë‹¤ìŒì€ ì„œìš¸ì‹œ êµ¬ì˜íšŒ íšŒì˜ë¡ ì „ì²´ ë‚´ìš©ì…ë‹ˆë‹¤. ì´ íšŒì˜ë¡ì—ì„œ ëª¨ë“  ì•ˆê±´ì„ ì°¾ì•„ì„œ ê°ê°ì˜ ì •ë³´ë¥¼ ì¶”ì¶œí•´ì£¼ì„¸ìš”.

íšŒì˜ë¡ ë‚´ìš©:
{content}

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•´ì£¼ì„¸ìš” (JSON ë°°ì—´ í˜•íƒœ):
[
  {{
    "agenda_title": "ì•ˆê±´ì˜ ì •í™•í•œ ì œëª©",
    "agenda_summary": "ì•ˆê±´ì˜ ìƒì„¸í•œ ë°°ê²½ê³¼ ëª©ì ì„ í¬í•¨í•œ ìš”ì•½",
    "agenda_impact": "ì´ ì•ˆê±´ì´ í†µê³¼ë˜ë©´ ì‹œë¯¼ë“¤ì˜ ì¼ìƒìƒí™œì— ì–´ë–¤ êµ¬ì²´ì ì¸ ë³€í™”ë‚˜ ì˜í–¥ì´ ìˆì„ì§€ë¥¼ ì‰½ê³  ëª…í™•í•˜ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”. ì „ë¬¸ìš©ì–´ë¥¼ í”¼í•˜ê³  ì¼ë°˜ ì‹œë¯¼ì´ ì´í•´í•˜ê¸° ì‰¬ìš´ ì–¸ì–´ë¡œ ì‹¤ì§ˆì ì¸ í˜œíƒì´ë‚˜ ë³€í™”ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.",
    "agenda_interests": ["ê´€ë ¨ ë¶„ì•¼ (êµìœ¡, ë¬¸í™”, ë³µì§€, í™˜ê²½, êµí†µ, ì•ˆì „, ê²½ì œ, ë³´ê±´ ì¤‘ 1-2ê°œ)"],
    "agenda_full_text": "í•´ë‹¹ ì•ˆê±´ê³¼ ê´€ë ¨ëœ íšŒì˜ë¡ì˜ ëª¨ë“  ë‚´ìš©ì„ ìƒì„¸íˆ í¬í•¨. ì•ˆê±´ ì œì•ˆì, ë°œì˜ì ì •ë³´, ì•ˆê±´ì˜ ë°°ê²½ê³¼ ëª©ì , ì£¼ìš” ë‚´ìš©, ì¡°ë¡€ì˜ ì„¸ë¶€ ì¡°í•­, ìœ„ì›íšŒì—ì„œì˜ ëª¨ë“  ì§ˆì˜ì‘ë‹µ ë‚´ìš©, ìœ„ì›ë“¤ì˜ ì˜ê²¬ê³¼ í† ë¡  ê³¼ì •, ì‹¬ì‚¬ ê²°ê³¼, ì¬ì„ìœ„ì› ìˆ˜, ì°¬ì„±/ë°˜ëŒ€ ìˆ˜, ê°€ê²°/ë¶€ê²° ì—¬ë¶€ ë“± í•´ë‹¹ ì•ˆê±´ê³¼ ê´€ë ¨ëœ ëª¨ë“  íšŒì˜ë¡ ë‚´ìš©ì„ ë¹ ì§ì—†ì´ ìì„¸íˆ í¬í•¨í•´ì£¼ì„¸ìš”. ìµœì†Œ 500ì ì´ìƒìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”."
  }}
]

ì•ˆê±´ ì¶”ì¶œ ê¸°ì¤€:
1. ì¡°ë¡€ì•ˆ, ì˜ˆì‚°ì•ˆ, ë™ì˜ì•ˆ, ìŠ¹ì¸ì•ˆ, ê²°ì˜ì•ˆ ë“± ì •ì‹ ì˜ì•ˆ
2. êµ¬ì •ì§ˆë¬¸, ê¸´ê¸‰í˜„ì•ˆì§ˆë¬¸ ë“± ì •ì±… ê´€ë ¨ ì§ˆì˜
3. 5ë¶„ ììœ ë°œì–¸ ì¤‘ ì •ì±… ì œì•ˆì´ë‚˜ í˜„ì•ˆ ì´ìŠˆ
4. ì œì™¸í•  ê²ƒ: íšŒê¸°ê²°ì •, ì„œëª…ì˜ì› ì„ ì¶œ, ìœ„ì› ì„ ì„ ë“± ì ˆì°¨ì  ì•ˆê±´

ì¤‘ìš”ì‚¬í•­ - agenda_full_text ì‘ì„± ì‹œ:
- í•´ë‹¹ ì•ˆê±´ê³¼ ê´€ë ¨ëœ íšŒì˜ë¡ì˜ ëª¨ë“  ë‚´ìš©ì„ í¬í•¨í•´ì£¼ì„¸ìš”
- ì•ˆê±´ ì œì•ˆì/ë°œì˜ìì˜ ë°œì–¸ ë‚´ìš© ì „ì²´
- ì•ˆê±´ì˜ ë°°ê²½ ì„¤ëª…ê³¼ ì œì • ëª©ì  ìƒì„¸ ë‚´ìš©
- ì¡°ë¡€ì˜ ì£¼ìš” ì¡°í•­ê³¼ ë‚´ìš© ì„¤ëª…
- ìœ„ì›íšŒì—ì„œ ë‚˜ì˜¨ ëª¨ë“  ì§ˆì˜ì™€ ë‹µë³€ ë‚´ìš©
- ìœ„ì›ë“¤ì˜ ì˜ê²¬, ìš°ë ¤ì‚¬í•­, ê°œì„  ì œì•ˆ ë“±
- í† ë¡  ê³¼ì •ì—ì„œ ë‚˜ì˜¨ ëª¨ë“  ë°œì–¸
- ìµœì¢… ì‹¬ì‚¬ ê²°ê³¼ì™€ ì˜ê²° ê³¼ì •
- ì ˆëŒ€ ìš”ì•½í•˜ì§€ ë§ê³  ê´€ë ¨ ë‚´ìš©ì„ ëª¨ë‘ ìì„¸íˆ ê¸°ë¡í•´ì£¼ì„¸ìš”
- ìµœì†Œ 500ì ì´ìƒ, ê°€ëŠ¥í•˜ë©´ 1000ì ì´ìƒìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”
"""
    
    try:
        response = client.chat.completions.create(
            model=MODEL_NAME,
            messages=[{"role": "user", "content": prompt}],
            temperature=0.3,
            max_tokens=8000  # ë” ê¸´ ì‘ë‹µì„ ìœ„í•´ í† í° ìˆ˜ ì¦ê°€
        )
        
        response_text = response.choices[0].message.content
        print(f"ğŸ” GPT ì‘ë‹µ ê¸¸ì´: {len(response_text)}ì")
        
        # JSON ì¶”ì¶œ - ê°„ë‹¨í•œ ë°©ë²•
        if '```json' in response_text:
            start_idx = response_text.find('```json') + 7
            end_idx = response_text.find('```', start_idx)
            if end_idx != -1:
                json_text = response_text[start_idx:end_idx].strip()
            else:
                print("âŒ ```json ë¸”ë¡ì˜ ëì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")
                return []
        elif '```' in response_text:
            start_idx = response_text.find('```') + 3
            end_idx = response_text.find('```', start_idx)
            if end_idx != -1:
                json_text = response_text[start_idx:end_idx].strip()
            else:
                print("âŒ ``` ë¸”ë¡ì˜ ëì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")
                return []
        else:
            # JSON í˜•íƒœ ê·¸ëŒ€ë¡œ ì‚¬ìš©
            json_text = response_text.strip()
        
        print(f"ğŸ” JSON í…ìŠ¤íŠ¸ ê¸¸ì´: {len(json_text)}ì")
        
        # JSON íŒŒì‹± - ì—¬ëŸ¬ ë‹¨ê³„ ì‹œë„
        parsing_attempts = [
            # 1. ì›ë³¸ ê·¸ëŒ€ë¡œ
            lambda x: json.loads(x),
            # 2. trailing comma ì œê±° (ê¸°ë³¸)
            lambda x: json.loads(re.sub(r',(\s*[}\]])', r'\1', x)),
            # 3. ë‹¤ì–‘í•œ comma ë¬¸ì œ í•´ê²°
            lambda x: json.loads(fix_json_commas(x)),
            # 4. ë” ì ê·¹ì ì¸ ì •ë¦¬ + comma ìˆ˜ì •
            lambda x: json.loads(fix_json_commas(re.sub(r'\s+', ' ', x.strip()))),
            # 5. ë¶ˆì™„ì „í•œ JSON ìˆ˜ì • ì‹œë„
            lambda x: json.loads(fix_incomplete_json(x))
        ]
        
        agendas = None
        for i, attempt in enumerate(parsing_attempts, 1):
            try:
                agendas = attempt(json_text)
                if i > 1:
                    print(f"ğŸ”§ JSON íŒŒì‹± ì„±ê³µ (ì‹œë„ {i}ë²ˆì§¸)")
                break
            except json.JSONDecodeError as e:
                if i < len(parsing_attempts):
                    continue
                else:
                    print(f"âŒ ëª¨ë“  JSON íŒŒì‹± ì‹œë„ ì‹¤íŒ¨. ë§ˆì§€ë§‰ ì—ëŸ¬: {e}")
                    print(f"ğŸ” JSON í…ìŠ¤íŠ¸ ì¼ë¶€: {json_text[:1000]}...")
                    return []
        
        if not isinstance(agendas, list):
            print("âŒ GPT ì‘ë‹µì´ ë°°ì—´ í˜•íƒœê°€ ì•„ë‹™ë‹ˆë‹¤!")
            return []
        
        print(f"ğŸ“‹ {len(agendas)}ê°œì˜ ì•ˆê±´ì„ ì„±ê³µì ìœ¼ë¡œ ì¶”ì¶œí–ˆìŠµë‹ˆë‹¤!")
        
        # ì ˆì°¨ì  ì•ˆê±´ í•„í„°ë§
        filtered_agendas = []
        for agenda in agendas:
            if not is_procedural_agenda(agenda.get('agenda_title', '')):
                filtered_agendas.append(agenda)
            else:
                print(f"ğŸ”„ ì ˆì°¨ì  ì•ˆê±´ ì œì™¸: {agenda.get('agenda_title', '')}")
        
        return filtered_agendas
        
    except Exception as e:
        print(f"âŒ GPT ì•ˆê±´ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
        return []

def is_procedural_agenda(title):
    """ì ˆì°¨ì  ì•ˆê±´ì¸ì§€ íŒë‹¨í•©ë‹ˆë‹¤."""
    procedural_keywords = [
        'íšŒê¸°', 'ì˜ì‚¬ì¼ì •', 'ì„œëª…ì˜ì›', 'ìœ„ì›ì¥ ì„ ì¶œ', 'ë¶€ìœ„ì›ì¥ ì„ ì¶œ', 
        'ìœ„ì› ì„ ì„', 'ìœ„ì›ì¥ ì„ ê±°', 'ë¶€ì˜ì¥ ì„ ê±°', 'ì˜ì¥ ì„ ê±°',
        'ì„œëª…ì˜ì› ì„ ì¶œ', 'íšŒì˜ë¡ ì„œëª…', 'ê°„ì‚¬ ì„ ì„',
        'ì„œëª…ì˜ì› ì„ ì„', 'ì˜ì‚¬ì¼ì •', 'íšŒì˜ ì¤‘ë‹¨', 'íšŒì˜ ì¬ê°œ',
        'ìœ„ì›ì¥ ì„ ì¶œ', 'ë¶€ìœ„ì›ì¥ ì„ ì¶œ', 'ê°„ì‚¬ ì„ ì„'
    ]
    
    return any(keyword in title for keyword in procedural_keywords)

def save_results_to_json(results, output_file_path):
    """ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤."""
    print(f"ğŸ’¾ ê²°ê³¼ë¥¼ {output_file_path}ì— ì €ì¥ ì¤‘...")
    
    os.makedirs(os.path.dirname(output_file_path), exist_ok=True)
    
    with open(output_file_path, 'w', encoding='utf-8') as file:
        json.dump(results, file, ensure_ascii=False, indent=2)
    
    print(f"âœ… ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {len(results)}ê°œ ì•ˆê±´")

def generate_agenda_id(comm_id, index):
    """comm_id ê¸°ë°˜ìœ¼ë¡œ ê³ ìœ í•œ agenda_idë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    return f"{comm_id}_{index:03d}"

def main_pipeline(json_file_path, output_path, comm_id_to_url):
    """ì „ì²´ íŒŒì´í”„ë¼ì¸ì„ ì‹¤í–‰í•©ë‹ˆë‹¤."""
    file_start_time = time.time()
    filename = os.path.basename(json_file_path).replace('.json', '')
    print(f"\nğŸš€ íŒŒì¼ ì²˜ë¦¬ ì‹œì‘: {filename}")
    
    # 1. ë°ì´í„° ë¡œë“œ
    data = load_data_from_json(json_file_path)
    
    all_results = []
    total_meetings = len(data)
    total_agendas_found = 0
    total_agendas_processed = 0
    
    # ì „ì²´ íšŒì˜ë¡ ì²˜ë¦¬
    print(f"ğŸ“Š ì´ {total_meetings}ê°œì˜ íšŒì˜ë¡ ì²˜ë¦¬ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤.")
    
    for meeting_idx, meeting in enumerate(data, 1):
        meeting_start_time = time.time()
        comm_id = meeting['comm_id']
        content = meeting['content']
        
        # êµ¬ ì´ë¦„ ì¶”ì¶œ
        district_name = get_district_name_from_comm_id(comm_id)
        
        print(f"\n--- {meeting_idx}/{total_meetings} íšŒì˜ë¡ ì²˜ë¦¬ ì‹œì‘ (íšŒì˜ë¡ID: {comm_id}, êµ¬ì˜íšŒ: {district_name}) ---")
        
        # 2. GPTë¥¼ ì‚¬ìš©í•˜ì—¬ íšŒì˜ë¡ ì „ì²´ì—ì„œ ëª¨ë“  ì•ˆê±´ ì¶”ì¶œ
        extracted_agendas = extract_all_agendas_with_gpt(content, comm_id)
        
        if not extracted_agendas:
            print("âš ï¸ ì¶”ì¶œëœ ì•ˆê±´ì´ ì—†ìŠµë‹ˆë‹¤.")
            meeting_elapsed = time.time() - meeting_start_time
            print(f"âœ… {comm_id} ì²˜ë¦¬ ì™„ë£Œ | ì¶”ì¶œëœ ì•ˆê±´: 0ê°œ | ì†Œìš”ì‹œê°„: {meeting_elapsed:.2f}ì´ˆ")
            continue
        
        total_agendas_found += len(extracted_agendas)
        print(f"ğŸ“‘ íšŒì˜ë¡ {comm_id}ì—ì„œ {len(extracted_agendas)}ê°œì˜ ì•ˆê±´ì„ ì¶”ì¶œí–ˆìŠµë‹ˆë‹¤.")
        
        # 3. ê° ì•ˆê±´ì— ëŒ€í•´ ê²°ê³¼ êµ¬ì„±
        for agenda_idx, agenda_info in enumerate(extracted_agendas, 1):
            agenda_title = agenda_info.get('agenda_title', '')
            
            print(f"ğŸ“„ ì•ˆê±´ {agenda_idx}: '{agenda_title[:50]}...' ì²˜ë¦¬ ì¤‘...")
            
            # comm_idë¡œ íšŒì˜ë¡ URL ì°¾ê¸°
            agenda_url = comm_id_to_url.get(comm_id, "")
            if agenda_url:
                print(f"ğŸ”— íšŒì˜ë¡ URL: {agenda_url}")
            else:
                print(f"âš ï¸ comm_id {comm_id}ì— í•´ë‹¹í•˜ëŠ” URLì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                agenda_url = ""  # ëª…ì‹œì ìœ¼ë¡œ ë¹ˆ ë¬¸ìì—´ ì„¤ì •
            
            # agenda_full_textëŠ” agenda_full_text ì‚¬ìš©
            agenda_full_text = agenda_info.get('agenda_full_text', '')
            
            # ê²°ê³¼ êµ¬ì„±
            result_item = {
                "comm_id": comm_id,
                "value": {
                    "agenda_id": generate_agenda_id(comm_id, agenda_idx),
                    "agenda_title": agenda_title,
                    "agenda_summary": agenda_info.get('agenda_summary', ''),
                    "agenda_impact": agenda_info.get('agenda_impact', ''),
                    "agenda_interests": agenda_info.get('agenda_interests', []),
                    "agenda_full_text": agenda_full_text,
                    "agenda_url": agenda_url
                }
            }
            
            all_results.append(result_item)
            total_agendas_processed += 1
            
            print(f"âœ… ì•ˆê±´ ì²˜ë¦¬ ì™„ë£Œ")
            print(f"ğŸ“„ ì•ˆê±´ ë‚´ìš© ê¸¸ì´: {len(agenda_full_text):,}ì")
        
        meeting_elapsed = time.time() - meeting_start_time
        print(f"âœ… {comm_id} ì²˜ë¦¬ ì™„ë£Œ | ì¶”ì¶œëœ ì•ˆê±´: {len(extracted_agendas)}ê°œ | ì†Œìš”ì‹œê°„: {meeting_elapsed:.2f}ì´ˆ")
    
    # 4. ê²°ê³¼ ì €ì¥
    output_file_path = os.path.join(output_path, f"{filename}_prep.json")
    save_results_to_json(all_results, output_file_path)
    
    # í†µê³„ ì¶œë ¥
    file_elapsed = time.time() - file_start_time
    print(f"\nğŸ“Š íŒŒì¼ ì²˜ë¦¬ ì™„ë£Œ í†µê³„:")
    print(f"   â€¢ íŒŒì¼ëª…: {filename}")
    print(f"   â€¢ ì²˜ë¦¬ëœ íšŒì˜ë¡: {total_meetings}ê°œ")
    print(f"   â€¢ ë°œê²¬ëœ ì´ ì•ˆê±´: {total_agendas_found}ê°œ")
    print(f"   â€¢ ì²˜ë¦¬ëœ ì´ ì•ˆê±´: {total_agendas_processed}ê°œ")
    print(f"   â€¢ ì´ ì†Œìš”ì‹œê°„: {file_elapsed:.2f}ì´ˆ")
    print(f"   â€¢ íšŒì˜ë¡ë‹¹ í‰ê·  ì‹œê°„: {file_elapsed/total_meetings:.2f}ì´ˆ")
    print(f"   â€¢ ì¶œë ¥ íŒŒì¼: {output_file_path}")

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    # í´ë” ê²½ë¡œ ì„¤ì •
    input_folder = "raw_content"
    output_folder = "output_content"
    meta_file_path = os.path.join(input_folder, "tb_meta_info.json")
    
    print("ğŸ” ì„œìš¸ì‹œ êµ¬ì˜íšŒ íšŒì˜ë¡ ì²˜ë¦¬ ì‹œìŠ¤í…œ (ê°„ì†Œí™” ë²„ì „)")
    print("="*60)
    
    # ë©”íƒ€ ì •ë³´ ë¡œë“œ
    if not os.path.exists(meta_file_path):
        print(f"âŒ ë©”íƒ€ ì •ë³´ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {meta_file_path}")
        exit(1)
    
    comm_id_to_url = load_meta_info(meta_file_path)
    
    # ì¶œë ¥ í´ë” ìƒì„±
    os.makedirs(output_folder, exist_ok=True)
    
    # JSON íŒŒì¼ ì°¾ê¸° (ë©”íƒ€ íŒŒì¼ ì œì™¸)
    json_files = [f for f in glob.glob(os.path.join(input_folder, "*.json")) 
                  if not f.endswith("tb_meta_info.json")]
    
    if not json_files:
        print(f"âŒ {input_folder} í´ë”ì— ì²˜ë¦¬í•  JSON íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        exit(1)
    
    total_start_time = time.time()
    print(f"ğŸ¯ ì „ì²´ ì²˜ë¦¬ ì‹œì‘: {len(json_files)}ê°œ íŒŒì¼")
    
    # ê° JSON íŒŒì¼ ì²˜ë¦¬
    for file_idx, json_file_path in enumerate(json_files, 1):
        print(f"\n{'='*60}")
        
        # íŒŒì¼ëª…ì—ì„œ êµ¬ ì½”ë“œ ì¶”ì¶œ
        filename = os.path.basename(json_file_path).replace('.json', '')
        district_code = filename.split('_')[-1] if '_' in filename else filename[:2]
        district_name = get_district_name_from_comm_id(district_code)
        
        print(f"ğŸ“ {file_idx}/{len(json_files)} íŒŒì¼ ì²˜ë¦¬ ì¤‘... ({district_name})")
        main_pipeline(json_file_path, output_folder, comm_id_to_url)
    
    # ì „ì²´ ì™„ë£Œ í†µê³„
    total_elapsed = time.time() - total_start_time
    print(f"\n{'='*60}")
    print(f"ğŸ‰ ì „ì²´ ì²˜ë¦¬ ì™„ë£Œ!")
    print(f"   â€¢ ì´ íŒŒì¼ ìˆ˜: {len(json_files)}ê°œ")
    print(f"   â€¢ ì´ ì†Œìš”ì‹œê°„: {total_elapsed:.2f}ì´ˆ")
    print(f"   â€¢ í‰ê·  íŒŒì¼ë‹¹ ì‹œê°„: {total_elapsed/len(json_files):.2f}ì´ˆ")
    print(f"   â€¢ ê²°ê³¼ ì €ì¥ í´ë”: {output_folder}")

if __name__ == "__main__":
    """
    ì‹¤í–‰ ë°©ë²•:
    1. í•„ìˆ˜ í™˜ê²½ë³€ìˆ˜ ì„¤ì •:
       - OPENAI_API_KEY: OpenAI API í‚¤
    
    2. í•„ìˆ˜ íŒŒì¼ í™•ì¸:
       - raw_content/ í´ë”ì— JSON íŒŒì¼ë“¤
       - raw_content/tb_meta_info.json (comm_idì™€ URL ë§¤í•‘)
    
    3. ì‹¤í–‰:
       python meeting_minutes_processor_simple.py
    """
    
    # í™˜ê²½ë³€ìˆ˜ í™•ì¸
    if not OPENAI_API_KEY:
        print("âŒ OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        print("   Windows: set OPENAI_API_KEY=your-api-key")
        print("   Linux/Mac: export OPENAI_API_KEY=your-api-key")
        exit(1)
    
    main()